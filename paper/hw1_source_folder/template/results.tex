
\section{Pre-Processing}
\label{sec:Pre-Processing}

\indent Before building the Ridge regression models for both Beach 6 and Huntington, we created several graphs with the assistance of ChatGPT to help us visualize the data and discover patterns to understand the nature of the dataset.

\begin{figure}[htb]

  \centering  

  \includegraphics[width=0.32\textwidth]{corr_heatmap.png}

  \caption{Beach~6 heatmap of variable correlation} 

  \label{fig:tex}

\end{figure}

\begin{figure}[htb]

  \centering  

  \includegraphics[width=0.37\textwidth]{corr_heatmap copy.png}

  \caption{Huntington heatmap of variable correlation} 

  \label{fig:tex}

\end{figure}

Figures 1 and 2 visualizes a heatmap, where red indicates a positive variable correlation, and blue indicates a negative correlation. It displays the correlations between E. coli and factors like turbidity, rainfall, and water temperature, highlighting the most influential predictors. They also reveal correlations among predictors, point to possible multicollinearity.

\begin{figure}[htb]

  \centering  

  \includegraphics[width=0.4\textwidth]{timeseries_ECOLI_LOG10_linear.png}

  \caption{Beach 6 time series plot that shows how E. coli concentrations change across the sampling period.} 

  \label{fig:tex}

\end{figure}


\begin{figure}[htb]

  \centering  

  \includegraphics[width=0.37\textwidth]{timeseries_EcoliAve_CFU.png}

  \caption{Huntington time series plot that shows how E. coli concentrations change across the sampling period.} 

  \label{fig:tex}

\end{figure}


Figures 3 and 4 display several noticeable spikes across both sites, which likely correspond to rainfall events, changes in lake level, or increases in turbidity. These peaks are important for identifying when water quality deteriorates and for linking environmental conditions to bacterial concentrations. The visualizations provide temporal context that supports the selection of predictors in the regression model.

\begin{figure}[htb]

  \centering  

  \includegraphics[width=0.37\textwidth]{scatter_ECOLI_LOG10_linear_vs_TURB_NTRU.png}

  \caption{Beach 6 scatter plot that shows the relationship between turbidity and E. coli.}

  \label{fig:tex}

\end{figure}



\begin{figure}[htb]

  \centering  

  \includegraphics[width=0.37\textwidth]{scatter_EcoliAve_CFU_vs_Lake_Turb_NTRU.png}

  \caption{Huntington scatter plot that shows the relationship between turbidity and E. coli.}

  \label{fig:tex}

\end{figure}


Figures 5 and 6 demonstrate that turbidity is strongly associated with E. coli at both Beach 6 and Huntington. The consistent positive correlation highlights a key linear relationship driving the regression model. This is important because turbidity serves as one of the most influential environmental predictors.


\subsection{Data Cleaning}

\indent For the Beach 6 calibration, we started by reading the calibration dataset and identifying the target variable, ECOLI\_LOG10. Several features were transformed for consistency with the existing USGS models. More specifically, turbidity values were log-transformed (LOG\_TURB), and rainfall over the past 48 hours was square-root transformed (SQRT\_RAIN48). 

\indent Furthermore, the validation dataset for Beach 6 went through similar feature transformations. However, once we began inspecting the validation dataset for Beach 6, we noticed that the dataset contained non-numeric values. Some E. coli measurements were reported as $<1$, representing values below the detection limit. Since the model requires numerical input and cannot interpret the $<$ symbol, these values were replaced with 0.5 prior to applying the log10 transformation. 

\indent Next, for the Huntington calibration data, the pre-processing steps were similar. The calibration dataset’s target variable, EcoliAve\_CFU, was log-transformed to EcoliAve\_CFU\_log10. Rainfall and wave height were square-root transformed, and lake turbidity was log-transformed. 

\indent During model evaluation, both the Huntington validation features (X\_valid) and the target variable (y\_valid) contained missing values. Specifically, X\_valid had missing values in Lake\_Turb\_NTRU\_log10 (1 missing), SQRT\_WaveHt (3 missing), and LL\_PreDay (7 missing), while y\_valid had 3 empty entries. Because Ridge regression cannot handle NaN values directly, we applied the \texttt{SimpleImputer} function from scikit-learn to replace missing feature values with the mean of the corresponding variable.  However, since missing values in the target variable cannot be imputed, the three rows with missing y\_valid entries were removed. This approach ensured that the model could be trained and evaluated only on complete observations.

\section{Model Implementation: Beach 6 and Huntington}
\label{sec:implementation}

\indent Ridge Regression models were used for both the Beach 6 and Huntington data. This was implemented using Python’s scikit-learn library. For both models, the calibration dataset was used to train the model, while the validation dataset was reserved for testing and assessing generalization. 

\indent First, we used hyperparameter tuning by  using GridSearchCV with a 5-fold cross-validation approach. The dataset was split into five subsets, iteratively training the model on four folds and validating on the fifth. The regularization parameter alpha was tested over a range of values [0.01, 0.1, 1, 10, 100]. This ensured that we generated a robust estimate of model performance.
    
\indent Next, based on cross-validation results, the optimal alpha was determined to be 1 for both, and the final Ridge model was trained on the full calibration dataset. Model performance on the calibration dataset was assessed using R² to measure explained variance and RMSE to quantify prediction error. Additionally, scatter plots of predicted versus actual values were generated to visualize model accuracy. 

\indent Lastly, to evaluate the models' generalization ability, the same feature transformations applied to the calibration dataset were applied to the validation sets, and the trained model was used to generate predictions. Calculating $R^2$ and RMSE on the validation datasets allowed us to determine how well the models performed on unseen data and to identify any potential overfitting. 


\section{Results}
\subsection{Model 1: Beach 6}
The results for Beach 6 showed that our Ridge regression model closely mirrored the original published model in both structure and performance. The fitted coefficients for key predictors, including turbidity, relative humidity, and water temperature, were nearly identical to those in the original model. On the calibration dataset, the model achieved an $R^2$ of 0.476 and an RMSE of 0.480, which are values that closely match the original model’s reported performance. This confirmed that the fitted coefficients and overall predictive structure remained stable. However, when applied to the validation dataset, performance declined, with $R^2$ dropping to 0.253 and RMSE increasing slightly to 0.489. This reduction in predictive accuracy highlights potential overfitting and indicates that while the model is effective within the calibration sample, it does not generalize as strongly to unseen data. An important factor is that the validation dataset contained only 100 observations, compared to the calibration data, which contains 463 water samples. So, the smaller dataset is most likely the cause of the higher variance estimates and less stable $R^2$ values. The scatter plot of predicted versus observed E. coli concentrations for the calibration dataset Figure 7 shows points clustering closely around the 1:1 line, while the corresponding validation scatter plot Figure 8 displays greater dispersion, reflecting the weaker performance on unseen data.

\begin{figure}[htb]

  \centering  

  \includegraphics[width=0.30\textwidth]{Calibration_Beach}

  \caption{Predicted vs Actual Values for calibration data (Beach 6)} 

  \label{fig:tex}

\end{figure}

\begin{figure}[htb]

  \centering  

  \includegraphics[width=0.30\textwidth]{Valid_beach.png}

  \caption{Predicted vs Actual Values for validation data (Beach 6)} 

  \label{fig:f}

\end{figure}

    
\subsection{Model 2: Huntington}
The Huntington model also closely mirrored the original published model in both structure and performance. The fitted coefficients were again closely aligned with those reported in the original study, specifically for turbidity, rainfall, and lake temperature. The model achieved an $R^2$ of 0.556 and an RMSE of 0.424 on the calibration dataset, slightly outperforming the original model in terms of predictive accuracy. But, as with Beach 6, validation performance revealed weaker generalization, with $R^2$ decreasing to 0.288 and RMSE rising to 0.569. Similar to the Beach 6 validation data, the Huntington validation data  contained fewer than 103 observations after cleaning, compared to the calibration data, which contains 1,011 water samples. So, the smaller dataset is most likely the cause of the higher variance estimates and less stable $R^2$ values. The scatter plot for calibration Figure 9 shows predictions aligning more closely with observed values along the 1:1 line. However, the validation scatter plot Figure 10 illustrates a wider spread of points, highlighting greater error and weaker performance on unseen data. 


\indent Together, the results show that the Ridge regression successfully replicated the coefficient patterns and predictive framework of the original models while also revealing the challenges of generalizing to new conditions.

\begin{figure}[htb]

  \centering  

  \includegraphics[width=0.30\textwidth]{Calib_Hunt.png}

  \caption{Predicted vs Actual Values for scikit-learn training data (Huntington)} 

  \label{fig:tex}

\end{figure}

\begin{figure}[htb]

  \centering  

  \includegraphics[width=0.30\textwidth]{Valid_Hunt.png}

  \caption{Predicted vs Actual Values for scikit-learn test data (Huntington)} 

  \label{fig:tex}

\end{figure}








